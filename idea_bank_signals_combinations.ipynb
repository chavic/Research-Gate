{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Advanced Signal Combinations Framework\n",
    "\n",
    "## Sophisticated Multi-Signal Trading Strategies\n",
    "\n",
    "This notebook implements **powerful combinations** of the advanced signals from our signal bank, creating robust multi-factor trading strategies that leverage signal synergies and reduce false positives.\n",
    "\n",
    "### ðŸŽ¯ **Combination Strategy Categories:**\n",
    "\n",
    "- **Regime-Aware Combinations** - Adapt strategy based on market conditions\n",
    "- **Confirmation-Based Strategies** - Multiple signals must agree\n",
    "- **Diversified Multi-Factor** - Combine uncorrelated signals\n",
    "- **Hierarchical Filtering** - Primary signals with secondary filters\n",
    "- **Ensemble Methods** - Weighted voting systems\n",
    "- **Dynamic Allocation** - Adjust signal weights based on performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Signal Combinations Framework Initialized\n",
      "ðŸŽ¯ Ready to create sophisticated multi-signal strategies\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# QuantConnect imports\n",
    "from AlgorithmImports import *\n",
    "\n",
    "# Set up QuantBook\n",
    "qb = QuantBook()\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ðŸš€ Signal Combinations Framework Initialized\")\n",
    "print(\"ðŸŽ¯ Ready to create sophisticated multi-signal strategies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regime-Aware Signal Combinations\n",
    "\n",
    "Adapt signal combinations based on market regime detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Regime-Aware Combinations implemented\n"
     ]
    }
   ],
   "source": [
    "class RegimeAwareCombinations:\n",
    "    \"\"\"\n",
    "    Regime-Aware Signal Combinations\n",
    "    Core Concept: Different signals work better in different market conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, signals_dict, data):\n",
    "        self.signals = signals_dict\n",
    "        self.data = data\n",
    "        self.combinations = {}\n",
    "    \n",
    "    def volatility_regime_strategy(self):\n",
    "        \"\"\"\n",
    "        Volatility Regime Strategy\n",
    "        High Vol: Use momentum signals (Fractal_Hurst, KAMA, Donchian)\n",
    "        Low Vol: Use mean-reversion signals (RSI, Bollinger, VWAP_ZScore)\n",
    "        \"\"\"\n",
    "        # Detect volatility regime\n",
    "        returns = self.data['close'].pct_change()\n",
    "        vol_20d = returns.rolling(20).std() * np.sqrt(252)\n",
    "        vol_regime = vol_20d > vol_20d.rolling(100).median()\n",
    "        \n",
    "        # High volatility signals (momentum)\n",
    "        momentum_signals = []\n",
    "        for signal_name in ['Fractal_Hurst', 'KAMA', 'Donchian_Breakout']:\n",
    "            if signal_name in self.signals:\n",
    "                momentum_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Low volatility signals (mean reversion)  \n",
    "        mean_rev_signals = []\n",
    "        for signal_name in ['VWAP_ZScore', 'BB_Squeeze', 'Round_Number_Psychology']:\n",
    "            if signal_name in self.signals:\n",
    "                mean_rev_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Combine based on regime\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            if vol_regime.iloc[i]:  # High volatility - use momentum\n",
    "                if momentum_signals:\n",
    "                    momentum_votes = [sig[i] for sig in momentum_signals]\n",
    "                    combined_signals[i] = np.sign(np.mean(momentum_votes))\n",
    "            else:  # Low volatility - use mean reversion\n",
    "                if mean_rev_signals:\n",
    "                    mean_rev_votes = [sig[i] for sig in mean_rev_signals]\n",
    "                    combined_signals[i] = np.sign(np.mean(mean_rev_votes))\n",
    "        \n",
    "        self.combinations['Volatility_Regime'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def trend_vs_chop_strategy(self):\n",
    "        \"\"\"\n",
    "        Trend vs Chop Strategy\n",
    "        Trending: Use trend-following signals\n",
    "        Choppy: Use contrarian signals\n",
    "        \"\"\"\n",
    "        # Detect trend vs chop using ADX-like measure\n",
    "        high_low = self.data['high'] - self.data['low']\n",
    "        close_prev = abs(self.data['close'] - self.data['close'].shift(1))\n",
    "        true_range = np.maximum(high_low, close_prev)\n",
    "        \n",
    "        # Directional movement\n",
    "        plus_dm = np.where(\n",
    "            (self.data['high'] - self.data['high'].shift(1)) > \n",
    "            (self.data['low'].shift(1) - self.data['low']),\n",
    "            np.maximum(self.data['high'] - self.data['high'].shift(1), 0), 0\n",
    "        )\n",
    "        minus_dm = np.where(\n",
    "            (self.data['low'].shift(1) - self.data['low']) > \n",
    "            (self.data['high'] - self.data['high'].shift(1)),\n",
    "            np.maximum(self.data['low'].shift(1) - self.data['low'], 0), 0\n",
    "        )\n",
    "        \n",
    "        # Trend strength\n",
    "        plus_di = 100 * pd.Series(plus_dm).rolling(14).mean() / true_range.rolling(14).mean()\n",
    "        minus_di = 100 * pd.Series(minus_dm).rolling(14).mean() / true_range.rolling(14).mean()\n",
    "        adx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)\n",
    "        \n",
    "        trending = adx > 25  # Strong trend\n",
    "        \n",
    "        # Trending signals\n",
    "        trend_signals = []\n",
    "        for signal_name in ['KAMA', 'Donchian_Breakout', 'ML_GradientBoosting']:\n",
    "            if signal_name in self.signals:\n",
    "                trend_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Choppy/contrarian signals\n",
    "        contrarian_signals = []\n",
    "        for signal_name in ['VWAP_ZScore', 'Gap_Fill', 'Vol_Spike_Fade']:\n",
    "            if signal_name in self.signals:\n",
    "                contrarian_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Combine based on regime\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            if trending.iloc[i]:  # Trending market\n",
    "                if trend_signals:\n",
    "                    trend_votes = [sig[i] for sig in trend_signals]\n",
    "                    combined_signals[i] = np.sign(np.mean(trend_votes))\n",
    "            else:  # Choppy market\n",
    "                if contrarian_signals:\n",
    "                    contrarian_votes = [sig[i] for sig in contrarian_signals]\n",
    "                    combined_signals[i] = np.sign(np.mean(contrarian_votes))\n",
    "        \n",
    "        self.combinations['Trend_vs_Chop'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def volume_regime_strategy(self):\n",
    "        \"\"\"\n",
    "        Volume Regime Strategy\n",
    "        High Volume: Trust breakout signals\n",
    "        Low Volume: Fade moves, expect reversals\n",
    "        \"\"\"\n",
    "        if 'volume' not in self.data.columns:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Volume regime detection\n",
    "        vol_ma = self.data['volume'].rolling(20).mean()\n",
    "        high_volume = self.data['volume'] > vol_ma * 1.5\n",
    "        \n",
    "        # High volume signals (breakouts)\n",
    "        breakout_signals = []\n",
    "        for signal_name in ['Donchian_Breakout', 'BB_Squeeze', 'OI_Surge']:\n",
    "            if signal_name in self.signals:\n",
    "                breakout_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Low volume signals (reversals)\n",
    "        reversal_signals = []\n",
    "        for signal_name in ['Gap_Fill', 'Momentum_Exhaustion', 'Weekend_Effect']:\n",
    "            if signal_name in self.signals:\n",
    "                reversal_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Combine based on volume regime\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            if high_volume.iloc[i]:  # High volume - trust breakouts\n",
    "                if breakout_signals:\n",
    "                    breakout_votes = [sig[i] for sig in breakout_signals]\n",
    "                    combined_signals[i] = np.sign(np.mean(breakout_votes))\n",
    "            else:  # Low volume - expect reversals\n",
    "                if reversal_signals:\n",
    "                    reversal_votes = [sig[i] for sig in reversal_signals]\n",
    "                    combined_signals[i] = np.sign(np.mean(reversal_votes))\n",
    "        \n",
    "        self.combinations['Volume_Regime'] = combined_signals\n",
    "        return combined_signals\n",
    "\n",
    "print(\"âœ… Regime-Aware Combinations implemented\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Confirmation-Based Strategies\n",
    "\n",
    "Multiple signals must agree before generating a trade signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Confirmation-Based Strategies implemented\n"
     ]
    }
   ],
   "source": [
    "class ConfirmationStrategies:\n",
    "    \"\"\"\n",
    "    Confirmation-Based Signal Combinations\n",
    "    Core Concept: Reduce false positives by requiring multiple signal agreement\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, signals_dict, data):\n",
    "        self.signals = signals_dict\n",
    "        self.data = data\n",
    "        self.combinations = {}\n",
    "    \n",
    "    def momentum_confirmation_strategy(self):\n",
    "        \"\"\"\n",
    "        Momentum Confirmation Strategy\n",
    "        Require 3+ momentum signals to agree for high-confidence trades\n",
    "        \"\"\"\n",
    "        momentum_signal_names = [\n",
    "            'Fractal_Hurst', 'KAMA', 'Donchian_Breakout', \n",
    "            'ML_GradientBoosting', 'RV_Regime'\n",
    "        ]\n",
    "        \n",
    "        momentum_signals = []\n",
    "        for signal_name in momentum_signal_names:\n",
    "            if signal_name in self.signals:\n",
    "                momentum_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if len(momentum_signals) < 3:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Calculate signal agreement\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            votes = [sig[i] for sig in momentum_signals]\n",
    "            bullish_votes = sum(1 for v in votes if v > 0)\n",
    "            bearish_votes = sum(1 for v in votes if v < 0)\n",
    "            total_votes = len([v for v in votes if v != 0])\n",
    "            \n",
    "            # Require 70% agreement and at least 3 signals\n",
    "            if total_votes >= 3:\n",
    "                if bullish_votes / total_votes >= 0.7:\n",
    "                    combined_signals[i] = 1\n",
    "                elif bearish_votes / total_votes >= 0.7:\n",
    "                    combined_signals[i] = -1\n",
    "        \n",
    "        self.combinations['Momentum_Confirmation'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def mean_reversion_confirmation_strategy(self):\n",
    "        \"\"\"\n",
    "        Mean Reversion Confirmation Strategy\n",
    "        Combine contrarian signals for high-probability reversals\n",
    "        \"\"\"\n",
    "        mean_rev_signal_names = [\n",
    "            'VWAP_ZScore', 'Gap_Fill', 'Round_Number_Psychology',\n",
    "            'Vol_Spike_Fade', 'Weekend_Effect', 'Momentum_Exhaustion'\n",
    "        ]\n",
    "        \n",
    "        mean_rev_signals = []\n",
    "        for signal_name in mean_rev_signal_names:\n",
    "            if signal_name in self.signals:\n",
    "                mean_rev_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if len(mean_rev_signals) < 2:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Calculate signal agreement\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            votes = [sig[i] for sig in mean_rev_signals]\n",
    "            bullish_votes = sum(1 for v in votes if v > 0)\n",
    "            bearish_votes = sum(1 for v in votes if v < 0)\n",
    "            total_votes = len([v for v in votes if v != 0])\n",
    "            \n",
    "            # Require 60% agreement for mean reversion\n",
    "            if total_votes >= 2:\n",
    "                if bullish_votes / total_votes >= 0.6:\n",
    "                    combined_signals[i] = 1\n",
    "                elif bearish_votes / total_votes >= 0.6:\n",
    "                    combined_signals[i] = -1\n",
    "        \n",
    "        self.combinations['Mean_Reversion_Confirmation'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def cross_timeframe_confirmation(self):\n",
    "        \"\"\"\n",
    "        Cross-Timeframe Confirmation\n",
    "        Combine fast and slow signals for robust entries\n",
    "        \"\"\"\n",
    "        # Fast signals (more reactive)\n",
    "        fast_signals = []\n",
    "        for signal_name in ['Day_of_Week', 'Funding_Reset_Fade', 'BB_Squeeze']:\n",
    "            if signal_name in self.signals:\n",
    "                fast_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Slow signals (more stable)\n",
    "        slow_signals = []\n",
    "        for signal_name in ['Fractal_Hurst', 'ML_RegimeClassifier', 'Month_End_Flow']:\n",
    "            if signal_name in self.signals:\n",
    "                slow_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if not fast_signals or not slow_signals:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Combine fast and slow signals\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            # Get fast signal consensus\n",
    "            fast_votes = [sig[i] for sig in fast_signals]\n",
    "            fast_consensus = np.sign(np.mean([v for v in fast_votes if v != 0])) if any(v != 0 for v in fast_votes) else 0\n",
    "            \n",
    "            # Get slow signal consensus\n",
    "            slow_votes = [sig[i] for sig in slow_signals]\n",
    "            slow_consensus = np.sign(np.mean([v for v in slow_votes if v != 0])) if any(v != 0 for v in slow_votes) else 0\n",
    "            \n",
    "            # Require both fast and slow to agree\n",
    "            if fast_consensus != 0 and slow_consensus != 0 and fast_consensus == slow_consensus:\n",
    "                combined_signals[i] = fast_consensus\n",
    "        \n",
    "        self.combinations['Cross_Timeframe_Confirmation'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def volume_price_confirmation(self):\n",
    "        \"\"\"\n",
    "        Volume-Price Confirmation Strategy\n",
    "        Combine price signals with volume confirmation\n",
    "        \"\"\"\n",
    "        # Price-based signals\n",
    "        price_signals = []\n",
    "        for signal_name in ['KAMA', 'Donchian_Breakout', 'Round_Number_Psychology']:\n",
    "            if signal_name in self.signals:\n",
    "                price_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Volume-based signals\n",
    "        volume_signals = []\n",
    "        for signal_name in ['CVD', 'VPT', 'OI_Surge']:\n",
    "            if signal_name in self.signals:\n",
    "                volume_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if not price_signals or not volume_signals:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Require both price and volume confirmation\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            # Price signal consensus\n",
    "            price_votes = [sig[i] for sig in price_signals]\n",
    "            price_consensus = np.sign(np.mean([v for v in price_votes if v != 0])) if any(v != 0 for v in price_votes) else 0\n",
    "            \n",
    "            # Volume signal consensus\n",
    "            volume_votes = [sig[i] for sig in volume_signals]\n",
    "            volume_consensus = np.sign(np.mean([v for v in volume_votes if v != 0])) if any(v != 0 for v in volume_votes) else 0\n",
    "            \n",
    "            # Both must agree\n",
    "            if price_consensus != 0 and volume_consensus != 0 and price_consensus == volume_consensus:\n",
    "                combined_signals[i] = price_consensus\n",
    "        \n",
    "        self.combinations['Volume_Price_Confirmation'] = combined_signals\n",
    "        return combined_signals\n",
    "\n",
    "print(\"âœ… Confirmation-Based Strategies implemented\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble & Weighted Voting Systems\n",
    "\n",
    "Advanced ensemble methods with dynamic weighting based on signal performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ensemble & Weighted Voting Systems implemented\n"
     ]
    }
   ],
   "source": [
    "class EnsembleStrategies:\n",
    "    \"\"\"\n",
    "    Ensemble & Weighted Voting Systems\n",
    "    Core Concept: Weight signals based on historical performance and combine intelligently\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, signals_dict, data):\n",
    "        self.signals = signals_dict\n",
    "        self.data = data\n",
    "        self.combinations = {}\n",
    "        self.signal_weights = {}\n",
    "    \n",
    "    def calculate_signal_weights(self, lookback_window=100):\n",
    "        \"\"\"\n",
    "        Calculate dynamic weights based on recent signal performance\n",
    "        \"\"\"\n",
    "        returns = self.data['close'].pct_change().shift(-1)  # Next period returns\n",
    "        \n",
    "        for signal_name, signals in self.signals.items():\n",
    "            if signal_name == 'Random_Baseline':\n",
    "                continue\n",
    "                \n",
    "            # Calculate signal returns\n",
    "            signal_returns = []\n",
    "            for i in range(len(signals)):\n",
    "                if signals[i] != 0 and i < len(returns) - 1:\n",
    "                    signal_returns.append(signals[i] * returns.iloc[i])\n",
    "            \n",
    "            if len(signal_returns) > 10:\n",
    "                # Recent performance (last lookback_window periods)\n",
    "                recent_returns = signal_returns[-lookback_window:] if len(signal_returns) > lookback_window else signal_returns\n",
    "                \n",
    "                # Weight based on Sharpe ratio\n",
    "                mean_return = np.mean(recent_returns)\n",
    "                std_return = np.std(recent_returns)\n",
    "                sharpe = mean_return / std_return if std_return > 0 else 0\n",
    "                \n",
    "                # Normalize weight (positive sharpe gets higher weight)\n",
    "                self.signal_weights[signal_name] = max(0, sharpe)\n",
    "            else:\n",
    "                self.signal_weights[signal_name] = 0.1  # Default small weight\n",
    "        \n",
    "        # Normalize weights to sum to 1\n",
    "        total_weight = sum(self.signal_weights.values())\n",
    "        if total_weight > 0:\n",
    "            for signal_name in self.signal_weights:\n",
    "                self.signal_weights[signal_name] /= total_weight\n",
    "    \n",
    "    def adaptive_weighted_ensemble(self):\n",
    "        \"\"\"\n",
    "        Adaptive Weighted Ensemble\n",
    "        Dynamically weight signals based on rolling performance\n",
    "        \"\"\"\n",
    "        self.calculate_signal_weights()\n",
    "        \n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            weighted_vote = 0\n",
    "            total_weight = 0\n",
    "            \n",
    "            for signal_name, signals in self.signals.items():\n",
    "                if signal_name in self.signal_weights and signals[i] != 0:\n",
    "                    weight = self.signal_weights[signal_name]\n",
    "                    weighted_vote += weight * signals[i]\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Convert to discrete signal\n",
    "            if total_weight > 0:\n",
    "                avg_vote = weighted_vote / total_weight\n",
    "                if avg_vote > 0.3:\n",
    "                    combined_signals[i] = 1\n",
    "                elif avg_vote < -0.3:\n",
    "                    combined_signals[i] = -1\n",
    "        \n",
    "        self.combinations['Adaptive_Weighted_Ensemble'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def confidence_weighted_ensemble(self):\n",
    "        \"\"\"\n",
    "        Confidence-Weighted Ensemble\n",
    "        Weight signals based on their confidence/strength\n",
    "        \"\"\"\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            votes = []\n",
    "            confidences = []\n",
    "            \n",
    "            for signal_name, signals in self.signals.items():\n",
    "                if signal_name == 'Random_Baseline':\n",
    "                    continue\n",
    "                    \n",
    "                if signals[i] != 0:\n",
    "                    # Calculate confidence based on signal consistency\n",
    "                    window_start = max(0, i - 10)\n",
    "                    recent_signals = signals[window_start:i+1]\n",
    "                    \n",
    "                    # Confidence = consistency of recent signals\n",
    "                    non_zero_signals = [s for s in recent_signals if s != 0]\n",
    "                    if len(non_zero_signals) > 0:\n",
    "                        same_direction = sum(1 for s in non_zero_signals if np.sign(s) == np.sign(signals[i]))\n",
    "                        confidence = same_direction / len(non_zero_signals)\n",
    "                    else:\n",
    "                        confidence = 0.5\n",
    "                    \n",
    "                    votes.append(signals[i])\n",
    "                    confidences.append(confidence)\n",
    "            \n",
    "            if votes:\n",
    "                # Weight votes by confidence\n",
    "                weighted_vote = sum(v * c for v, c in zip(votes, confidences))\n",
    "                total_confidence = sum(confidences)\n",
    "                \n",
    "                if total_confidence > 0:\n",
    "                    avg_vote = weighted_vote / total_confidence\n",
    "                    if avg_vote > 0.4:\n",
    "                        combined_signals[i] = 1\n",
    "                    elif avg_vote < -0.4:\n",
    "                        combined_signals[i] = -1\n",
    "        \n",
    "        self.combinations['Confidence_Weighted_Ensemble'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def diversified_portfolio_approach(self):\n",
    "        \"\"\"\n",
    "        Diversified Portfolio Approach\n",
    "        Combine uncorrelated signals to reduce overall strategy risk\n",
    "        \"\"\"\n",
    "        # Group signals by category\n",
    "        signal_categories = {\n",
    "            'momentum': ['Fractal_Hurst', 'KAMA', 'Donchian_Breakout', 'ML_GradientBoosting'],\n",
    "            'mean_reversion': ['VWAP_ZScore', 'Gap_Fill', 'Round_Number_Psychology', 'Vol_Spike_Fade'],\n",
    "            'volume': ['CVD', 'VPT', 'OI_Surge'],\n",
    "            'seasonality': ['Day_of_Week', 'Funding_Reset_Fade', 'Month_End_Flow', 'Weekend_Effect'],\n",
    "            'behavioral': ['Momentum_Exhaustion', 'Round_Number_Psychology']\n",
    "        }\n",
    "        \n",
    "        # Calculate category signals\n",
    "        category_signals = {}\n",
    "        for category, signal_names in signal_categories.items():\n",
    "            category_votes = []\n",
    "            for signal_name in signal_names:\n",
    "                if signal_name in self.signals:\n",
    "                    category_votes.append(self.signals[signal_name])\n",
    "            \n",
    "            if category_votes:\n",
    "                # Average signals within category\n",
    "                category_signal = np.mean(category_votes, axis=0)\n",
    "                category_signals[category] = np.sign(category_signal)\n",
    "        \n",
    "        # Combine categories with equal weight\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            votes = [cat_sig[i] for cat_sig in category_signals.values() if cat_sig[i] != 0]\n",
    "            \n",
    "            if len(votes) >= 2:  # Require at least 2 categories to agree\n",
    "                avg_vote = np.mean(votes)\n",
    "                if avg_vote > 0.3:\n",
    "                    combined_signals[i] = 1\n",
    "                elif avg_vote < -0.3:\n",
    "                    combined_signals[i] = -1\n",
    "        \n",
    "        self.combinations['Diversified_Portfolio'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def machine_learning_ensemble(self):\n",
    "        \"\"\"\n",
    "        Machine Learning Ensemble\n",
    "        Use ML to learn optimal signal combinations\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            from sklearn.model_selection import train_test_split\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ Scikit-learn not available for ML ensemble\")\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Prepare features (all signals as features)\n",
    "        feature_matrix = []\n",
    "        feature_names = []\n",
    "        \n",
    "        for signal_name, signals in self.signals.items():\n",
    "            if signal_name != 'Random_Baseline':\n",
    "                feature_matrix.append(signals)\n",
    "                feature_names.append(signal_name)\n",
    "        \n",
    "        if len(feature_matrix) < 3:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        X = np.array(feature_matrix).T  # Transpose to get samples x features\n",
    "        \n",
    "        # Target: next period return direction\n",
    "        returns = self.data['close'].pct_change().shift(-1)\n",
    "        y = (returns > 0).astype(int)\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_indices = ~np.isnan(returns)\n",
    "        X = X[valid_indices]\n",
    "        y = y[valid_indices]\n",
    "        \n",
    "        if len(X) < 100:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Train-test split\n",
    "        split_idx = int(len(X) * 0.7)\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        # Train Random Forest\n",
    "        rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Generate predictions\n",
    "        predictions = rf.predict_proba(X_test)[:, 1]  # Probability of up move\n",
    "        \n",
    "        # Convert to signals\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        test_start_idx = split_idx\n",
    "        \n",
    "        for i, prob in enumerate(predictions):\n",
    "            if test_start_idx + i < len(combined_signals):\n",
    "                if prob > 0.6:\n",
    "                    combined_signals[test_start_idx + i] = 1\n",
    "                elif prob < 0.4:\n",
    "                    combined_signals[test_start_idx + i] = -1\n",
    "        \n",
    "        self.combinations['ML_Ensemble'] = combined_signals\n",
    "        return combined_signals\n",
    "\n",
    "print(\"âœ… Ensemble & Weighted Voting Systems implemented\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical & Filter-Based Combinations\n",
    "\n",
    "Primary signals with secondary filters and hierarchical decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hierarchical & Filter-Based Combinations implemented\n"
     ]
    }
   ],
   "source": [
    "class HierarchicalStrategies:\n",
    "    \"\"\"\n",
    "    Hierarchical & Filter-Based Combinations\n",
    "    Core Concept: Use primary signals with secondary filters for enhanced precision\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, signals_dict, data):\n",
    "        self.signals = signals_dict\n",
    "        self.data = data\n",
    "        self.combinations = {}\n",
    "    \n",
    "    def momentum_with_volatility_filter(self):\n",
    "        \"\"\"\n",
    "        Momentum Strategy with Volatility Filter\n",
    "        Primary: Momentum signals (KAMA, Fractal_Hurst)\n",
    "        Filter: Only trade in appropriate volatility regime\n",
    "        \"\"\"\n",
    "        # Primary momentum signals\n",
    "        momentum_signals = []\n",
    "        for signal_name in ['KAMA', 'Fractal_Hurst', 'Donchian_Breakout']:\n",
    "            if signal_name in self.signals:\n",
    "                momentum_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if not momentum_signals:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Volatility filter\n",
    "        returns = self.data['close'].pct_change()\n",
    "        vol_20d = returns.rolling(20).std() * np.sqrt(252)\n",
    "        vol_percentile = vol_20d.rolling(100).rank(pct=True)\n",
    "        \n",
    "        # Trade momentum only in medium-high volatility (40th-80th percentile)\n",
    "        vol_filter = (vol_percentile > 0.4) & (vol_percentile < 0.8)\n",
    "        \n",
    "        # Combine momentum signals\n",
    "        momentum_consensus = np.mean(momentum_signals, axis=0)\n",
    "        \n",
    "        # Apply filter\n",
    "        combined_signals = np.where(\n",
    "            vol_filter & (momentum_consensus > 0.3), 1,\n",
    "            np.where(vol_filter & (momentum_consensus < -0.3), -1, 0)\n",
    "        )\n",
    "        \n",
    "        self.combinations['Momentum_Vol_Filter'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def mean_reversion_with_trend_filter(self):\n",
    "        \"\"\"\n",
    "        Mean Reversion with Trend Filter\n",
    "        Primary: Mean reversion signals\n",
    "        Filter: Only trade against weak trends, not strong ones\n",
    "        \"\"\"\n",
    "        # Primary mean reversion signals\n",
    "        mean_rev_signals = []\n",
    "        for signal_name in ['VWAP_ZScore', 'Gap_Fill', 'Vol_Spike_Fade']:\n",
    "            if signal_name in self.signals:\n",
    "                mean_rev_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if not mean_rev_signals:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Trend strength filter (using moving averages)\n",
    "        sma_20 = self.data['close'].rolling(20).mean()\n",
    "        sma_50 = self.data['close'].rolling(50).mean()\n",
    "        \n",
    "        # Weak trend: MAs are close together\n",
    "        ma_spread = abs(sma_20 - sma_50) / sma_50\n",
    "        weak_trend = ma_spread < 0.05  # Less than 5% spread\n",
    "        \n",
    "        # Combine mean reversion signals\n",
    "        mean_rev_consensus = np.mean(mean_rev_signals, axis=0)\n",
    "        \n",
    "        # Apply filter - only trade mean reversion in weak trends\n",
    "        combined_signals = np.where(\n",
    "            weak_trend & (mean_rev_consensus > 0.3), 1,\n",
    "            np.where(weak_trend & (mean_rev_consensus < -0.3), -1, 0)\n",
    "        )\n",
    "        \n",
    "        self.combinations['MeanRev_Trend_Filter'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def breakout_with_volume_confirmation(self):\n",
    "        \"\"\"\n",
    "        Breakout Strategy with Volume Confirmation\n",
    "        Primary: Breakout signals\n",
    "        Filter: Require volume confirmation\n",
    "        \"\"\"\n",
    "        # Primary breakout signals\n",
    "        breakout_signals = []\n",
    "        for signal_name in ['Donchian_Breakout', 'BB_Squeeze', 'Range_Compression']:\n",
    "            if signal_name in self.signals:\n",
    "                breakout_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if not breakout_signals or 'volume' not in self.data.columns:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Volume confirmation filter\n",
    "        vol_ma = self.data['volume'].rolling(20).mean()\n",
    "        high_volume = self.data['volume'] > vol_ma * 1.3\n",
    "        \n",
    "        # Combine breakout signals\n",
    "        breakout_consensus = np.mean(breakout_signals, axis=0)\n",
    "        \n",
    "        # Apply volume filter\n",
    "        combined_signals = np.where(\n",
    "            high_volume & (breakout_consensus > 0.3), 1,\n",
    "            np.where(high_volume & (breakout_consensus < -0.3), -1, 0)\n",
    "        )\n",
    "        \n",
    "        self.combinations['Breakout_Volume_Filter'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def ml_primary_with_seasonal_filter(self):\n",
    "        \"\"\"\n",
    "        ML Primary with Seasonal Filter\n",
    "        Primary: ML signals\n",
    "        Filter: Seasonal timing filters\n",
    "        \"\"\"\n",
    "        # Primary ML signals\n",
    "        ml_signals = []\n",
    "        for signal_name in ['ML_GradientBoosting', 'ML_RegimeClassifier']:\n",
    "            if signal_name in self.signals:\n",
    "                ml_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        if not ml_signals:\n",
    "            return np.zeros(len(self.data))\n",
    "        \n",
    "        # Seasonal filters\n",
    "        seasonal_signals = []\n",
    "        for signal_name in ['Day_of_Week', 'Month_End_Flow', 'Weekend_Effect']:\n",
    "            if signal_name in self.signals:\n",
    "                seasonal_signals.append(self.signals[signal_name])\n",
    "        \n",
    "        # Combine ML signals\n",
    "        ml_consensus = np.mean(ml_signals, axis=0)\n",
    "        \n",
    "        # Apply seasonal filter\n",
    "        if seasonal_signals:\n",
    "            seasonal_consensus = np.mean(seasonal_signals, axis=0)\n",
    "            # Only trade when seasonal signals don't contradict\n",
    "            seasonal_neutral = abs(seasonal_consensus) < 0.3\n",
    "            \n",
    "            combined_signals = np.where(\n",
    "                seasonal_neutral & (ml_consensus > 0.4), 1,\n",
    "                np.where(seasonal_neutral & (ml_consensus < -0.4), -1, 0)\n",
    "            )\n",
    "        else:\n",
    "            combined_signals = np.where(\n",
    "                ml_consensus > 0.4, 1,\n",
    "                np.where(ml_consensus < -0.4, -1, 0)\n",
    "            )\n",
    "        \n",
    "        self.combinations['ML_Seasonal_Filter'] = combined_signals\n",
    "        return combined_signals\n",
    "    \n",
    "    def hierarchical_decision_tree(self):\n",
    "        \"\"\"\n",
    "        Hierarchical Decision Tree\n",
    "        Multi-level decision process with different signal priorities\n",
    "        \"\"\"\n",
    "        combined_signals = np.zeros(len(self.data))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            # Level 1: Check regime signals first\n",
    "            regime_vote = 0\n",
    "            regime_count = 0\n",
    "            \n",
    "            for signal_name in ['RV_Regime', 'ML_RegimeClassifier']:\n",
    "                if signal_name in self.signals and self.signals[signal_name][i] != 0:\n",
    "                    regime_vote += self.signals[signal_name][i]\n",
    "                    regime_count += 1\n",
    "            \n",
    "            if regime_count > 0:\n",
    "                regime_consensus = regime_vote / regime_count\n",
    "                \n",
    "                # Level 2: Based on regime, choose appropriate signals\n",
    "                if regime_consensus > 0.3:  # Bullish regime\n",
    "                    # Use momentum signals\n",
    "                    momentum_vote = 0\n",
    "                    momentum_count = 0\n",
    "                    \n",
    "                    for signal_name in ['KAMA', 'Donchian_Breakout', 'Fractal_Hurst']:\n",
    "                        if signal_name in self.signals and self.signals[signal_name][i] != 0:\n",
    "                            momentum_vote += self.signals[signal_name][i]\n",
    "                            momentum_count += 1\n",
    "                    \n",
    "                    if momentum_count >= 2:  # Require at least 2 momentum signals\n",
    "                        momentum_consensus = momentum_vote / momentum_count\n",
    "                        if momentum_consensus > 0.5:\n",
    "                            combined_signals[i] = 1\n",
    "                \n",
    "                elif regime_consensus < -0.3:  # Bearish regime\n",
    "                    # Use defensive/contrarian signals\n",
    "                    defensive_vote = 0\n",
    "                    defensive_count = 0\n",
    "                    \n",
    "                    for signal_name in ['VWAP_ZScore', 'Gap_Fill', 'Vol_Spike_Fade']:\n",
    "                        if signal_name in self.signals and self.signals[signal_name][i] != 0:\n",
    "                            defensive_vote += self.signals[signal_name][i]\n",
    "                            defensive_count += 1\n",
    "                    \n",
    "                    if defensive_count >= 2:\n",
    "                        defensive_consensus = defensive_vote / defensive_count\n",
    "                        if defensive_consensus < -0.5:\n",
    "                            combined_signals[i] = -1\n",
    "                        elif defensive_consensus > 0.5:  # Counter-trend opportunity\n",
    "                            combined_signals[i] = 1\n",
    "                \n",
    "                # Level 3: Apply final filters\n",
    "                # Volume filter\n",
    "                if 'volume' in self.data.columns:\n",
    "                    vol_ma = self.data['volume'].rolling(20).mean()\n",
    "                    if i >= 20 and self.data['volume'].iloc[i] < vol_ma.iloc[i] * 0.7:\n",
    "                        combined_signals[i] = 0  # Cancel signal on very low volume\n",
    "        \n",
    "        self.combinations['Hierarchical_Decision_Tree'] = combined_signals\n",
    "        return combined_signals\n",
    "\n",
    "print(\"âœ… Hierarchical & Filter-Based Combinations implemented\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Combination Testing Framework\n",
    "\n",
    "Test all combination strategies and rank their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Comprehensive Combination Testing Framework implemented\n"
     ]
    }
   ],
   "source": [
    "def run_all_combination_strategies(signals_dict, data):\n",
    "    \"\"\"\n",
    "    Run all combination strategies and return comprehensive results\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ Running ALL Signal Combination Strategies...\")\n",
    "    print(f\"ðŸ“Š Available signals: {list(signals_dict.keys())}\")\n",
    "    \n",
    "    all_combinations = {}\n",
    "    \n",
    "    # Initialize all combination classes\n",
    "    regime_aware = RegimeAwareCombinations(signals_dict, data)\n",
    "    confirmation = ConfirmationStrategies(signals_dict, data)\n",
    "    ensemble = EnsembleStrategies(signals_dict, data)\n",
    "    hierarchical = HierarchicalStrategies(signals_dict, data)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Calculating Regime-Aware Combinations...\")\n",
    "    try:\n",
    "        vol_regime = regime_aware.volatility_regime_strategy()\n",
    "        all_combinations['Volatility_Regime'] = vol_regime\n",
    "        print(\"âœ… Volatility Regime Strategy\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Volatility Regime failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        trend_chop = regime_aware.trend_vs_chop_strategy()\n",
    "        all_combinations['Trend_vs_Chop'] = trend_chop\n",
    "        print(\"âœ… Trend vs Chop Strategy\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Trend vs Chop failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        volume_regime = regime_aware.volume_regime_strategy()\n",
    "        all_combinations['Volume_Regime'] = volume_regime\n",
    "        print(\"âœ… Volume Regime Strategy\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Volume Regime failed: {e}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Calculating Confirmation-Based Strategies...\")\n",
    "    try:\n",
    "        momentum_conf = confirmation.momentum_confirmation_strategy()\n",
    "        all_combinations['Momentum_Confirmation'] = momentum_conf\n",
    "        print(\"âœ… Momentum Confirmation\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Momentum Confirmation failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        mean_rev_conf = confirmation.mean_reversion_confirmation_strategy()\n",
    "        all_combinations['Mean_Reversion_Confirmation'] = mean_rev_conf\n",
    "        print(\"âœ… Mean Reversion Confirmation\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Mean Reversion Confirmation failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        cross_timeframe = confirmation.cross_timeframe_confirmation()\n",
    "        all_combinations['Cross_Timeframe_Confirmation'] = cross_timeframe\n",
    "        print(\"âœ… Cross-Timeframe Confirmation\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Cross-Timeframe Confirmation failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        vol_price_conf = confirmation.volume_price_confirmation()\n",
    "        all_combinations['Volume_Price_Confirmation'] = vol_price_conf\n",
    "        print(\"âœ… Volume-Price Confirmation\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Volume-Price Confirmation failed: {e}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Calculating Ensemble Strategies...\")\n",
    "    try:\n",
    "        adaptive_ensemble = ensemble.adaptive_weighted_ensemble()\n",
    "        all_combinations['Adaptive_Weighted_Ensemble'] = adaptive_ensemble\n",
    "        print(\"âœ… Adaptive Weighted Ensemble\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Adaptive Weighted Ensemble failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        confidence_ensemble = ensemble.confidence_weighted_ensemble()\n",
    "        all_combinations['Confidence_Weighted_Ensemble'] = confidence_ensemble\n",
    "        print(\"âœ… Confidence Weighted Ensemble\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Confidence Weighted Ensemble failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        diversified = ensemble.diversified_portfolio_approach()\n",
    "        all_combinations['Diversified_Portfolio'] = diversified\n",
    "        print(\"âœ… Diversified Portfolio\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Diversified Portfolio failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        ml_ensemble = ensemble.machine_learning_ensemble()\n",
    "        all_combinations['ML_Ensemble'] = ml_ensemble\n",
    "        print(\"âœ… ML Ensemble\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ML Ensemble failed: {e}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Calculating Hierarchical Strategies...\")\n",
    "    try:\n",
    "        momentum_vol_filter = hierarchical.momentum_with_volatility_filter()\n",
    "        all_combinations['Momentum_Vol_Filter'] = momentum_vol_filter\n",
    "        print(\"âœ… Momentum with Volatility Filter\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Momentum Vol Filter failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        mean_rev_trend_filter = hierarchical.mean_reversion_with_trend_filter()\n",
    "        all_combinations['MeanRev_Trend_Filter'] = mean_rev_trend_filter\n",
    "        print(\"âœ… Mean Reversion with Trend Filter\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Mean Rev Trend Filter failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        breakout_vol_filter = hierarchical.breakout_with_volume_confirmation()\n",
    "        all_combinations['Breakout_Volume_Filter'] = breakout_vol_filter\n",
    "        print(\"âœ… Breakout with Volume Filter\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Breakout Volume Filter failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        ml_seasonal_filter = hierarchical.ml_primary_with_seasonal_filter()\n",
    "        all_combinations['ML_Seasonal_Filter'] = ml_seasonal_filter\n",
    "        print(\"âœ… ML with Seasonal Filter\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ML Seasonal Filter failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        hierarchical_tree = hierarchical.hierarchical_decision_tree()\n",
    "        all_combinations['Hierarchical_Decision_Tree'] = hierarchical_tree\n",
    "        print(\"âœ… Hierarchical Decision Tree\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Hierarchical Decision Tree failed: {e}\")\n",
    "    \n",
    "    # Add random baseline for comparison\n",
    "    np.random.seed(42)\n",
    "    random_signals = np.random.choice([-1, 0, 1], size=len(data), p=[0.3, 0.4, 0.3])\n",
    "    all_combinations['Random_Baseline'] = random_signals\n",
    "    print(\"âœ… Random Baseline added\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Successfully calculated {len(all_combinations)} combination strategies!\")\n",
    "    return all_combinations\n",
    "\n",
    "# Performance analysis for combinations\n",
    "class CombinationPerformanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze performance of all combination strategies\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def analyze_combination_performance(self, data, signals, strategy_name):\n",
    "        \"\"\"\n",
    "        Analyze performance of a combination strategy\n",
    "        \"\"\"\n",
    "        # Calculate forward returns\n",
    "        forward_returns = data['close'].pct_change().shift(-1)\n",
    "        \n",
    "        # Signal performance metrics\n",
    "        long_signals = signals == 1\n",
    "        short_signals = signals == -1\n",
    "        \n",
    "        if np.sum(long_signals) > 0:\n",
    "            long_returns = forward_returns[long_signals]\n",
    "            avg_long_return = long_returns.mean()\n",
    "            long_win_rate = (long_returns > 0).mean()\n",
    "        else:\n",
    "            avg_long_return = 0\n",
    "            long_win_rate = 0\n",
    "        \n",
    "        if np.sum(short_signals) > 0:\n",
    "            short_returns = -forward_returns[short_signals]\n",
    "            avg_short_return = short_returns.mean()\n",
    "            short_win_rate = (short_returns > 0).mean()\n",
    "        else:\n",
    "            avg_short_return = 0\n",
    "            short_win_rate = 0\n",
    "        \n",
    "        # Overall metrics\n",
    "        signal_returns = np.where(signals == 1, forward_returns,\n",
    "                                 np.where(signals == -1, -forward_returns, 0))\n",
    "        \n",
    "        total_return = np.sum(signal_returns)\n",
    "        avg_return = np.mean(signal_returns[signals != 0]) if np.sum(signals != 0) > 0 else 0\n",
    "        volatility = np.std(signal_returns[signals != 0]) if np.sum(signals != 0) > 0 else 0\n",
    "        sharpe_ratio = avg_return / volatility if volatility > 0 else 0\n",
    "        \n",
    "        # Signal frequency\n",
    "        signal_frequency = np.sum(signals != 0) / len(signals)\n",
    "        \n",
    "        # Calmar ratio (return / max drawdown)\n",
    "        cumulative_returns = np.cumsum(signal_returns)\n",
    "        running_max = np.maximum.accumulate(cumulative_returns)\n",
    "        drawdown = running_max - cumulative_returns\n",
    "        max_drawdown = np.max(drawdown) if len(drawdown) > 0 else 0\n",
    "        calmar_ratio = total_return / max_drawdown if max_drawdown > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'strategy_name': strategy_name,\n",
    "            'total_return': total_return,\n",
    "            'avg_return': avg_return,\n",
    "            'volatility': volatility,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'calmar_ratio': calmar_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'signal_frequency': signal_frequency,\n",
    "            'long_return': avg_long_return,\n",
    "            'short_return': avg_short_return,\n",
    "            'long_win_rate': long_win_rate,\n",
    "            'short_win_rate': short_win_rate,\n",
    "            'total_signals': np.sum(signals != 0)\n",
    "        }\n",
    "    \n",
    "    def run_comprehensive_combination_analysis(self, data, all_combinations):\n",
    "        \"\"\"\n",
    "        Run comprehensive analysis on all combination strategies\n",
    "        \"\"\"\n",
    "        all_performance = []\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Analyzing {len(all_combinations)} combination strategies...\")\n",
    "        \n",
    "        for strategy_name, signals in all_combinations.items():\n",
    "            try:\n",
    "                performance = self.analyze_combination_performance(data, signals, strategy_name)\n",
    "                all_performance.append(performance)\n",
    "                print(f\"âœ… {strategy_name}: Sharpe {performance['sharpe_ratio']:.3f}, Calmar {performance['calmar_ratio']:.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {strategy_name} analysis failed: {e}\")\n",
    "        \n",
    "        # Create performance DataFrame\n",
    "        performance_df = pd.DataFrame(all_performance)\n",
    "        return performance_df.sort_values('sharpe_ratio', ascending=False)\n",
    "\n",
    "print(\"âœ… Comprehensive Combination Testing Framework implemented\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary & Recommended Combinations\n",
    "\n",
    "### ðŸŽ¯ **Top Signal Combination Strategies**\n",
    "\n",
    "Based on theoretical foundations and practical considerations, here are the most promising combinations:\n",
    "\n",
    "#### **ðŸ† Tier 1: High-Confidence Combinations**\n",
    "\n",
    "1. **Volatility Regime Strategy**\n",
    "   - **Logic**: Use momentum signals in high-vol periods, mean-reversion in low-vol\n",
    "   - **Signals**: Fractal_Hurst + KAMA + Donchian (high vol) | VWAP_ZScore + BB_Squeeze (low vol)\n",
    "   - **Edge**: Adapts to market conditions automatically\n",
    "\n",
    "2. **Momentum Confirmation Strategy**\n",
    "   - **Logic**: Require 70% agreement from 3+ momentum signals\n",
    "   - **Signals**: Fractal_Hurst + KAMA + Donchian_Breakout + ML_GradientBoosting + RV_Regime\n",
    "   - **Edge**: Reduces false positives through consensus\n",
    "\n",
    "3. **Adaptive Weighted Ensemble**\n",
    "   - **Logic**: Weight signals by recent Sharpe ratio performance\n",
    "   - **Signals**: All signals with dynamic weights\n",
    "   - **Edge**: Self-improving system that adapts to changing conditions\n",
    "\n",
    "#### **ðŸ¥ˆ Tier 2: Robust Combinations**\n",
    "\n",
    "4. **Hierarchical Decision Tree**\n",
    "   - **Logic**: Multi-level decision process with regime detection first\n",
    "   - **Signals**: RV_Regime â†’ Momentum or Contrarian â†’ Volume filter\n",
    "   - **Edge**: Structured approach mimics professional trading\n",
    "\n",
    "5. **Cross-Timeframe Confirmation**\n",
    "   - **Logic**: Fast signals confirmed by slow signals\n",
    "   - **Signals**: Day_of_Week + Funding_Reset (fast) | Fractal_Hurst + ML_Regime (slow)\n",
    "   - **Edge**: Combines different time horizons\n",
    "\n",
    "6. **Volume-Price Confirmation**\n",
    "   - **Logic**: Price signals must be confirmed by volume\n",
    "   - **Signals**: KAMA + Donchian + Round_Numbers | CVD + VPT + OI_Surge\n",
    "   - **Edge**: Ensures institutional participation\n",
    "\n",
    "#### **ðŸ¥‰ Tier 3: Specialized Combinations**\n",
    "\n",
    "7. **Breakout with Volume Filter**\n",
    "   - **Logic**: Only trade breakouts with volume confirmation\n",
    "   - **Signals**: Donchian + BB_Squeeze + Range_Compression + Volume > 1.3x MA\n",
    "   - **Edge**: High-probability breakout trades\n",
    "\n",
    "8. **Mean Reversion with Trend Filter**\n",
    "   - **Logic**: Only mean-revert in weak trend environments\n",
    "   - **Signals**: VWAP_ZScore + Gap_Fill + Vol_Spike_Fade (when MA spread < 5%)\n",
    "   - **Edge**: Avoids fighting strong trends\n",
    "\n",
    "9. **ML with Seasonal Filter**\n",
    "   - **Logic**: ML predictions filtered by seasonal patterns\n",
    "   - **Signals**: ML_GradientBoosting + ML_RegimeClassifier (when seasonal neutral)\n",
    "   - **Edge**: Combines AI with calendar effects\n",
    "\n",
    "### ðŸ“Š **Implementation Priority**\n",
    "\n",
    "**Start with**: Volatility Regime Strategy (easiest to implement, strong theoretical basis)\n",
    "**Add next**: Momentum Confirmation Strategy (reduces noise)\n",
    "**Advanced**: Adaptive Weighted Ensemble (requires performance tracking)\n",
    "\n",
    "### âš ï¸ **Key Implementation Notes**\n",
    "\n",
    "1. **Data Requirements**: Ensure you have OHLCV data with sufficient history\n",
    "2. **Regime Detection**: Critical for adaptive strategies - test regime detection accuracy\n",
    "3. **Signal Lag**: Account for calculation delays in live trading\n",
    "4. **Transaction Costs**: Factor in realistic costs for combination strategies\n",
    "5. **Risk Management**: Implement position sizing and stop-losses\n",
    "\n",
    "### ðŸ”¬ **Testing Methodology**\n",
    "\n",
    "- **Walk-Forward Analysis**: Test on rolling windows\n",
    "- **Cross-Validation**: Validate across different market periods\n",
    "- **Monte Carlo**: Test robustness with bootstrap sampling\n",
    "- **Live Paper Trading**: Validate before real money\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**: Run the comprehensive testing framework to validate these theoretical rankings with actual performance data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation-Py-Default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
