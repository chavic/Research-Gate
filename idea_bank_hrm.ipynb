{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Hierarchical Reasoning Model (HRM) for Next-Price Prediction\n","\n","This note adapts the Hierarchical Reasoning Model (HRM) to short-horizon market forecasting (e.g., next-tick or next-bar midprice change). HRM performs latent multi-step reasoning in a single forward pass by coupling two recurrent modules operating at different timescales: a slow high-level planner (H) and a fast low-level solver (L). It avoids chain-of-thought tokens and expensive BPTT by using a 1-step gradient approximation with deep supervision and adaptive computation time (ACT).\n","\n","### Why HRM for markets\n","- **Latent multi-step reasoning**: Markets often require iterative hypothesis–test–refine loops (e.g., infer regime → test microstructure cues → revise). HRM executes these loops internally without emitting token-level thoughts.\n","- **Depth without BPTT**: HRM achieves large effective compute depth (N cycles × T low-level steps) with O(1) memory backprop, fitting long contexts and large batches.\n","- **Adaptive runtime (ACT)**: Variable difficulty across timesteps/instruments; HRM learns when to “ponder” more or halt early based on uncertainty and expected reward.\n","- **Data efficiency**: Works well with small supervised datasets by reusing state across cycles and applying deep supervision.\n","\n","### Problem definition\n","- **Goal**: Predict short-horizon next price behavior for execution or alpha generation.\n","- **Targets** (choose per use case):\n","  - Regression: next midprice change Δp_{t+1} or log-return r_{t+1}.\n","  - Classification: direction sign(Δp_{t+1}) or thresholded move (e.g., |Δp| > κ).\n","  - Optional auxiliary: volatility σ̂_{t+1}, spread class, liquidity regime.\n","- **Latency budget**: Sub-millisecond to milliseconds depending on venue; ACT lets us trade accuracy for compute at inference.\n","\n","### Inputs and feature design\n","- **Core time-series window**: length L_in (e.g., 256–1024):\n","  - OHLCV, mid/bid/ask, spread, depth snapshots (top-K levels), imbalance, order flow (initiator, trade size), cancel/modify counts.\n","  - Returns and signed returns at multiple scales; realized vol, microprice, queue imbalance, Kyle’s λ proxies.\n","  - Calendar/time-of-day, session flags, volatility/regime embeddings.\n","  - Instrument meta: tick size, lot size, exchange, sector.\n","- **Preprocessing**:\n","  - Robust scaling per instrument (rolling z-score, median/MAD), ceiling outliers, log-transform volumes.\n","  - Align asynchronous events; pad/pack sequences; mask missing.\n","  - Label smoothing for classification; log-cosh/Huber targets for regression.\n","\n","### HRM architecture (market adaptation)\n","- Input network `fI`: embeds continuous feature vectors at each timestep (linear + RMSNorm + GLU). Optionally include learned positional encodings.\n","- Low-level recurrent module `fL`: encoder-only Transformer block stack (2–8 blocks) updated every low-level step; receives current H-state, prior L-state, and embedded inputs.\n","- High-level recurrent module `fH`: encoder-only Transformer block stack (2–8 blocks) updated once per cycle using the final L-state; evolves a slower plan/regime representation.\n","- Output heads `fO` on `z_H`:\n","  - Regression head (log-cosh/Huber); classification head (BCE/focal); optional volatility head; confidence head (e.g., temperature or predictive std).\n","  - Q-head for ACT to decide halt/continue.\n","- Effective depth: N high-level cycles × T low-level steps per cycle.\n","\n","### Training mechanics\n","- **1-step gradient approximation**: Backprop only through the most recent states of L and H, treating earlier steps as constants. O(1) memory, no BPTT unroll.\n","- **Deep supervision over segments**:\n","  - Run M segments; after each segment, compute loss on `fO(z_H)`; detach state before next segment.\n","  - Acts like iterative refinement with frequent feedback; stabilizes training similar to DEQ deep supervision.\n","- **Adaptive Computation Time (ACT)**:\n","  - Q-head predicts `Q(halt), Q(continue)` from `z_H` each segment.\n","  - Choose halt if `Q(halt) ≥ Q(continue)` and minimum segment threshold `M_min` reached; force halt at `M_max`.\n","  - Train Q-head with episodic Q-learning targets; add optional ponder-cost penalty λ_p for each extra segment.\n","- **Loss** (example multi-task):\n","  - L_reg = logcosh(ŷ_reg, y_reg) or Huber; L_dir = BCEWithLogits(ŷ_cls, y_dir); calibration (ECE/temperature) as post-hoc or auxiliary; L_Q = BCE(Q̂, Ĝ). Total: L = w_r L_reg + w_d L_dir + w_q L_Q.\n","- **Optimization & init**:\n","  - AdamW (scale-invariant Adam-atan2 variant works well), constant LR with warmup, weight decay.\n","  - Post-Norm, RMSNorm, GLU FFN, Rotary Positional Embeddings.\n","  - Truncated LeCun normal initialization; gradient clip (1.0); bf16/AMP.\n","- **Batching**:\n","  - Pack sequences by length; randomize instruments/time; stratify by regimes to reduce drift; reset hidden states between samples.\n","\n","### Inference & deployment\n","- **Inference-time scaling**: Increase `M_max` on hard cases (low confidence, large residuals) for extra accuracy; keep small `M_max` for easy cases.\n","- **Decision policy**:\n","  - Predict ŷ and confidence c; if c < τ, raise `M_max` or abstain; route to slower model if needed.\n","  - Optional ensemble across light augmentations (feature dropout, small jitter) and average.\n","- **Latency controls**: Cap T and N; set `M_max` per venue; prune heads not used online.\n","- **Calibration**: Temperature scaling or isotonic on a validation stream; monitor drift.\n","\n","### Metrics\n","- Pointwise: MAE/MSE of Δp or r; directional accuracy; AUC/PR for hit-rate; calibration (ECE, NLL).\n","- Trading: PnL with simple execution model (crossing spread or half-spread), turnover, drawdown, IR; latency SLA.\n","- Stability: Error by regime, by spread/vol bucket, and across time.\n","\n","### Recommended starting configuration\n","- d_model: 256–512; heads: 8; FFN multiplier: 2–4×; blocks per module: 4.\n","- N cycles: 2–4; T steps: 4–8; M_max (train): 2–4; M_max (inference): 2 for easy, up to 8 on demand.\n","- Sequence length L_in: 512; horizon: next tick/bar; batch size: as fits GPU with bf16.\n","- Loss: log-cosh for regression, optional direction BCE; w_r = 1.0, w_d = 0.25, w_q = 0.1.\n","- Optimizer: AdamW/Adam-atan2, LR 1e-3–2e-4 with 2k warmup; weight decay 0.01.\n","\n","### Minimal PyTorch-style sketch (pseudo-code)\n","```python\n","class HRM(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.input_net = InputEmbed(cfg)\n","        self.low = TransformerStack(cfg.low)\n","        self.high = TransformerStack(cfg.high)\n","        self.reg_head = nn.Linear(cfg.d_model, 1)\n","        self.cls_head = nn.Linear(cfg.d_model, 1)\n","        self.q_head = nn.Linear(cfg.d_model, 2)\n","\n","    def forward_segment(self, zH, zL, x, N, T):\n","        x_emb = self.input_net(x)\n","        with torch.no_grad():\n","            for i in range(N * T - 1):\n","                zL = self.low(zL, zH, x_emb)\n","                if (i + 1) % T == 0:\n","                    zH = self.high(zH, zL)\n","        # 1-step grad\n","        zL = self.low(zL, zH, x_emb)\n","        zH = self.high(zH, zL)\n","        reg = self.reg_head(zH)\n","        cls = self.cls_head(zH)\n","        q = self.q_head(zH)\n","        return (zH, zL), reg, cls, q\n","```\n","\n","```python\n","# Training loop with deep supervision + ACT (sketch)\n","for batch in loader:\n","    x, y_reg, y_dir = batch\n","    zH = init_state(batch_size, d_model)\n","    zL = init_state(batch_size, d_model)\n","    m = 0\n","    halted = torch.zeros(batch_size, dtype=torch.bool)\n","    while m < M_max:\n","        (zH, zL), reg, cls, q = model.forward_segment(zH, zL, x, N, T)\n","        # losses for non-halted samples\n","        mask = ~halted\n","        L = w_r * log_cosh(reg[mask], y_reg[mask])\n","        if use_dir:\n","            L = L + w_d * bce_with_logits(cls[mask], y_dir[mask])\n","        # Q-learning targets Ĝ for halt/continue (episodic); add ponder-cost if desired\n","        L = L + w_q * bce(q[mask], Ghat[mask])\n","        L.backward(); opt.step(); opt.zero_grad()\n","        # decide halting per sample\n","        act = (q[...,0] >= q[...,1]) & (m + 1 >= M_min)\n","        halted = halted | act\n","        # detach state across segments\n","        zH = zH.detach(); zL = zL.detach()\n","        m += 1\n","        if halted.all():\n","            break\n","```\n","\n","### Practical tips & pitfalls\n","- Prevent leakage: build labels strictly forward-only; respect exchange calendar and microstructure delays.\n","- Normalize per instrument with rolling stats; re-estimate periodically to track drift.\n","- Use robust losses (log-cosh/Huber) and clip grads to handle spikes.\n","- Start without ACT to validate pipeline; then enable ACT with small `M_max` and modest ponder-cost.\n","- Monitor calibration; miscalibrated confidence can harm ACT decisions.\n","- Ablate: HRM vs same-parameter Transformer (no recursion); −ACT; vary N, T.\n","\n","### Milestones\n","1) Data/label pipeline + baseline Transformer. 2) HRM (no ACT) with deep supervision. 3) Enable ACT and halting. 4) Inference-time scaling policy by confidence. 5) Calibration + live metrics (PnL, latency). 6) Hyperparameter sweep and ablations.\n","\n","References: HRM core ideas adapted from Hierarchical Reasoning Model (2025), with market-specific design choices for time-series forecasting.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Minimal HRM implementation + synthetic test\n","# Imports and config\n","import math\n","import random\n","from dataclasses import dataclass\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","set_seed(42)\n","\n","\n","@dataclass\n","class Config:\n","    # data\n","    seq_len: int = 256\n","    feature_dim: int = 16\n","    train_size: int = 2000\n","    val_size: int = 500\n","    batch_size: int = 64\n","\n","    # model\n","    d_model: int = 256\n","    n_cycles: int = 2  # N\n","    t_steps: int = 4   # T\n","    n_segments: int = 2  # M (deep supervision segments); set >1 to mimic refinement\n","\n","    # optimization\n","    lr: float = 2e-3\n","    weight_decay: float = 1e-2\n","    max_epochs: int = 3\n","    grad_clip: float = 1.0\n","\n","\n","cfg = Config()\n","print({\"device\": str(device)})\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Synthetic dataset for next-step prediction\n","class SyntheticMarketDataset(Dataset):\n","    \"\"\"\n","    Generates synthetic multivariate sequences and next-step return targets.\n","\n","    Latent AR(2) price process with regime switching and nonlinear microstructure noise.\n","    Features include lagged returns, rolling stats, and exogenous noise proxies.\n","    \"\"\"\n","    def __init__(self, num_samples: int, seq_len: int, feature_dim: int):\n","        self.num_samples = num_samples\n","        self.seq_len = seq_len\n","        self.feature_dim = feature_dim\n","        self.X, self.y = self._generate()\n","\n","    def _generate(self):\n","        X = np.zeros((self.num_samples, self.seq_len, self.feature_dim), dtype=np.float32)\n","        y = np.zeros((self.num_samples,), dtype=np.float32)\n","\n","        for i in range(self.num_samples):\n","            # regime: mean-reverting vs trending\n","            regime = np.random.choice([0, 1])\n","            if regime == 0:\n","                a1, a2 = 0.6, -0.2\n","            else:\n","                a1, a2 = 1.1, -0.3\n","\n","            price = np.zeros(self.seq_len + 2, dtype=np.float32)\n","            ret = np.zeros_like(price)\n","\n","            # generate AR(2) returns with heteroscedastic noise\n","            price[0] = 0.0\n","            price[1] = np.random.randn() * 0.01\n","            for t in range(2, self.seq_len + 2):\n","                eps = np.random.randn() * (0.005 + 0.01 * np.random.beta(2, 5))\n","                ret[t] = a1 * (price[t - 1] - price[t - 2]) + a2 * (price[t - 2] - price[t - 3] if t >= 3 else 0.0) + eps\n","                price[t] = price[t - 1] + ret[t]\n","\n","            seq_price = price[2:self.seq_len + 2]\n","            seq_ret = np.diff(seq_price, prepend=seq_price[0])\n","\n","            # features\n","            feat = np.zeros((self.seq_len, self.feature_dim), dtype=np.float32)\n","            feat[:, 0] = seq_ret\n","            # multi-scale returns\n","            for k, win in enumerate([2, 4, 8, 16], start=1):\n","                r = np.convolve(seq_ret, np.ones(win, dtype=np.float32) / win, mode=\"same\")\n","                feat[:, k] = r\n","            # realized volatility proxy\n","            rv = np.sqrt(np.convolve(seq_ret ** 2, np.ones(8, dtype=np.float32) / 8, mode=\"same\") + 1e-8)\n","            feat[:, 5] = rv\n","            # imbalance / microprice proxies (synthetic)\n","            feat[:, 6] = np.tanh(np.convolve(seq_ret, np.array([1, -1, 1, -1], dtype=np.float32), mode=\"same\"))\n","            feat[:, 7] = (rv > np.median(rv)).astype(np.float32)\n","            # exogenous noise features\n","            noise = np.random.randn(self.seq_len, self.feature_dim - 8).astype(np.float32) * 0.1\n","            feat[:, 8:] = noise\n","\n","            # next-step target (regression): next return\n","            target = ret[self.seq_len + 1]\n","\n","            X[i] = feat\n","            y[i] = target\n","\n","        # robust scaling per feature\n","        med = np.median(X, axis=(0, 1), keepdims=True)\n","        mad = np.median(np.abs(X - med), axis=(0, 1), keepdims=True) + 1e-6\n","        X = np.clip((X - med) / (1.4826 * mad), -5.0, 5.0)\n","\n","        return X, y\n","\n","    def __len__(self):\n","        return self.num_samples\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","\n","# Build loaders\n","train_ds = SyntheticMarketDataset(cfg.train_size, cfg.seq_len, cfg.feature_dim)\n","val_ds = SyntheticMarketDataset(cfg.val_size, cfg.seq_len, cfg.feature_dim)\n","\n","train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, drop_last=False)\n","\n","len(train_loader), len(val_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# HRM model modules\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model: int, max_len: int = 4096):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False)  # (1, max_len, d)\n","\n","    def forward(self, x):\n","        # x: (B, L, d)\n","        L = x.size(1)\n","        return x + self.pe[:, :L, :]\n","\n","\n","class InputEmbed(nn.Module):\n","    def __init__(self, feature_dim: int, d_model: int):\n","        super().__init__()\n","        self.proj = nn.Sequential(\n","            nn.Linear(feature_dim, d_model),\n","            nn.GELU(),\n","            nn.Linear(d_model, d_model)\n","        )\n","        self.norm = nn.LayerNorm(d_model)\n","        self.pos = PositionalEncoding(d_model)\n","\n","    def forward(self, x):\n","        # x: (B, L, F)\n","        h = self.proj(x)\n","        h = self.norm(h)\n","        h = self.pos(h)\n","        return h\n","\n","\n","class TransformerStack(nn.Module):\n","    def __init__(self, d_model: int, n_heads: int = 8, n_layers: int = 4, dim_ff: int = None, dropout: float = 0.0):\n","        super().__init__()\n","        if dim_ff is None:\n","            dim_ff = d_model * 2\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=n_heads,\n","            dim_feedforward=dim_ff,\n","            dropout=dropout,\n","            batch_first=True,\n","            activation=\"gelu\",\n","            norm_first=True,\n","        )\n","        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n","\n","    def forward(self, x):\n","        # x: (B, L, d)\n","        return self.encoder(x)\n","\n","\n","class HRM(nn.Module):\n","    def __init__(self, feature_dim: int, d_model: int = 256, n_heads: int = 8, n_layers_low: int = 4, n_layers_high: int = 4, dim_ff: int = None):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.input_net = InputEmbed(feature_dim, d_model)\n","        self.low = TransformerStack(d_model, n_heads=n_heads, n_layers=n_layers_low, dim_ff=dim_ff)\n","        self.high = TransformerStack(d_model, n_heads=n_heads, n_layers=n_layers_high, dim_ff=dim_ff)\n","        self.reg_head = nn.Linear(d_model, 1)\n","\n","    def init_state(self, batch_size: int, seq_len: int, device):\n","        zH = torch.zeros(batch_size, seq_len, self.d_model, device=device)\n","        zL = torch.zeros_like(zH)\n","        return zH, zL\n","\n","    def forward_segment(self, zH, zL, x, N: int, T: int):\n","        # x: (B, L, F)\n","        x_emb = self.input_net(x)\n","        # No-grad for N*T - 1 steps\n","        with torch.no_grad():\n","            for i in range(N * T - 1):\n","                # Low module updates fast within cycle\n","                l_in = x_emb + zL + zH\n","                zL = self.low(l_in)\n","                # High module updates every T steps\n","                if (i + 1) % T == 0:\n","                    h_in = zH + zL\n","                    zH = self.high(h_in)\n","        # 1-step grad-enabled update\n","        l_in = x_emb + zL + zH\n","        zL = self.low(l_in)\n","        h_in = zH + zL\n","        zH = self.high(h_in)\n","        # Heads on pooled high state\n","        pooled = zH.mean(dim=1)\n","        reg = self.reg_head(pooled).squeeze(-1)\n","        return (zH, zL), reg\n","\n","\n","model = HRM(feature_dim=cfg.feature_dim, d_model=cfg.d_model).to(device)\n","model\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Training loop with deep supervision (fixed segments), no ACT\n","opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","\n","\n","def log_cosh_loss(pred, target):\n","    x = pred - target\n","    return torch.log(torch.cosh(x + 1e-12)).mean()\n","\n","\n","def train_one_epoch(epoch):\n","    model.train()\n","    total = 0.0\n","    n = 0\n","    for xb, yb in train_loader:\n","        xb = xb.to(device)\n","        yb = yb.to(device)\n","        # initialize states\n","        zH, zL = model.init_state(xb.size(0), xb.size(1), device)\n","        seg_losses = []\n","        for m in range(cfg.n_segments):\n","            (zH, zL), reg = model.forward_segment(zH, zL, xb, cfg.n_cycles, cfg.t_steps)\n","            loss = log_cosh_loss(reg, yb)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n","            opt.step()\n","            opt.zero_grad(set_to_none=True)\n","            # detach state before next segment\n","            zH = zH.detach(); zL = zL.detach()\n","            seg_losses.append(loss.item())\n","        total += float(np.mean(seg_losses))\n","        n += 1\n","    print(f\"epoch {epoch} train loss: {total / max(n,1):.4f}\")\n","\n","\n","def evaluate():\n","    model.eval()\n","    losses = []\n","    maes = []\n","    with torch.no_grad():\n","        for xb, yb in val_loader:\n","            xb = xb.to(device)\n","            yb = yb.to(device)\n","            zH, zL = model.init_state(xb.size(0), xb.size(1), device)\n","            for m in range(cfg.n_segments):\n","                (zH, zL), reg = model.forward_segment(zH, zL, xb, cfg.n_cycles, cfg.t_steps)\n","                # no deep supervision updates; just get last segment pred\n","                zH = zH.detach(); zL = zL.detach()\n","            loss = log_cosh_loss(reg, yb).item()\n","            mae = (reg - yb).abs().mean().item()\n","            losses.append(loss)\n","            maes.append(mae)\n","    print(f\"val loss: {np.mean(losses):.4f} | val mae: {np.mean(maes):.5f}\")\n","\n","\n","for epoch in range(1, cfg.max_epochs + 1):\n","    train_one_epoch(epoch)\n","    evaluate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# BTC-USD data ingestion, feature engineering, sequence datasets, and model reinit\n","import pandas as pd\n","\n","# 1) Fetch BTC-USD data (1h)\n","try:\n","    import yfinance as yf\n","except ImportError:\n","    import sys, subprocess\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"yfinance\"])  # silent install\n","    import yfinance as yf\n","\n","symbol = \"BTC-USD\"\n","interval = \"1h\"\n","start_date = \"2020-01-01\"\n","print({\"fetch\": symbol, \"interval\": interval, \"start\": start_date})\n","\n","df = yf.download(symbol, start=start_date, interval=interval, auto_adjust=True, progress=False)\n","assert not df.empty, \"No BTC data fetched. Check internet or adjust date/interval.\"\n","\n","df = df.dropna().copy()\n","# Ensure columns\n","cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n","for c in cols:\n","    assert c in df.columns, f\"Missing column {c} in BTC data\"\n","\n","# 2) Feature engineering\n","close = df[\"Close\"].astype(np.float32).values\n","high = df[\"High\"].astype(np.float32).values\n","low = df[\"Low\"].astype(np.float32).values\n","vol = df[\"Volume\"].astype(np.float32).values\n","\n","# log returns\n","eps = 1e-12\n","ret1 = np.log(np.clip(close[1:] / np.clip(close[:-1], eps, None), eps, None)).astype(np.float32)\n","ret1 = np.concatenate([[0.0], ret1])\n","\n","# rolling utilities\n","def rolling_mean(x, w):\n","    k = np.ones(w, dtype=np.float32) / float(w)\n","    return np.convolve(x, k, mode=\"same\")\n","\n","def rolling_std(x, w):\n","    m = rolling_mean(x, w)\n","    m2 = rolling_mean(x * x, w)\n","    v = np.clip(m2 - m * m, 0.0, None)\n","    return np.sqrt(v + 1e-8)\n","\n","# EMAs\n","def ema(x, span):\n","    a = 2.0 / (span + 1.0)\n","    y = np.zeros_like(x, dtype=np.float32)\n","    y[0] = x[0]\n","    for i in range(1, len(x)):\n","        y[i] = a * x[i] + (1 - a) * y[i - 1]\n","    return y\n","\n","# RSI\n","def rsi(x, period=14):\n","    dx = np.diff(x, prepend=x[0])\n","    up = np.clip(dx, 0, None)\n","    dn = np.clip(-dx, 0, None)\n","    up_ema = ema(up, period)\n","    dn_ema = ema(dn, period)\n","    rs = up_ema / (dn_ema + 1e-8)\n","    r = 100.0 - (100.0 / (1.0 + rs))\n","    return r.astype(np.float32)\n","\n","# Features (aim ~16 dims)\n","feat_list = []\n","feat_list.append(ret1)                                                    # 0: ret1\n","for w in [2, 4, 8, 16]:\n","    feat_list.append(rolling_mean(ret1, w))                               # 1..4: mean returns\n","rv = rolling_std(ret1, 16)                                                # 5: rolling vol (returns std)\n","feat_list.append(rv)\n","feat_list.append(((high - low) / np.clip(close, eps, None)))              # 6: HL range / price\n","ema8 = ema(close, 8)\n","ema21 = ema(close, 21)\n","feat_list.append((close - ema8) / np.clip(close, eps, None))              # 7: deviation from EMA8\n","feat_list.append((close - ema21) / np.clip(close, eps, None))             # 8: deviation from EMA21\n","feat_list.append(rsi(close, 14) / 100.0)                                  # 9: RSI scaled\n","feat_list.append(np.log1p(vol))                                           # 10: log volume\n","feat_list.append(rolling_std(rv, 16))                                     # 11: vol of vol\n","\n","# time features (UTC index)\n","idx = df.index\n","if isinstance(idx, pd.DatetimeIndex):\n","    hour = idx.hour.values.astype(np.float32)\n","    dow = idx.dayofweek.values.astype(np.float32)\n","else:\n","    # fallback to zeros\n","    hour = np.zeros(len(df), dtype=np.float32)\n","    dow = np.zeros(len(df), dtype=np.float32)\n","feat_list.append(np.sin(2 * np.pi * hour / 24.0))                         # 12: sin hour\n","feat_list.append(np.cos(2 * np.pi * hour / 24.0))                         # 13: cos hour\n","feat_list.append(np.sin(2 * np.pi * dow / 7.0))                           # 14: sin dow\n","feat_list.append(np.cos(2 * np.pi * dow / 7.0))                           # 15: cos dow\n","\n","features = np.stack(feat_list, axis=1).astype(np.float32)                 # (T, F)\n","Fdim = features.shape[1]\n","\n","# robust scale per feature\n","med = np.median(features, axis=0, keepdims=True)\n","mad = np.median(np.abs(features - med), axis=0, keepdims=True) + 1e-6\n","features = np.clip((features - med) / (1.4826 * mad), -5.0, 5.0)\n","\n","# Targets: next-step log return\n","targets = np.roll(ret1, -1).astype(np.float32)\n","features = features[:-1]\n","targets = targets[:-1]\n","\n","print({\"T\": len(features), \"F\": Fdim})\n","\n","# 3) Build windowed sequences\n","class WindowedSeqDataset(Dataset):\n","    def __init__(self, feats: np.ndarray, targs: np.ndarray, seq_len: int):\n","        self.X = feats\n","        self.y = targs\n","        self.seq_len = seq_len\n","        self.N = max(0, len(self.X) - seq_len)\n","\n","    def __len__(self):\n","        return self.N\n","\n","    def __getitem__(self, idx):\n","        x = self.X[idx: idx + self.seq_len]\n","        y = self.y[idx + self.seq_len - 1]  # next-step after window end\n","        return x.astype(np.float32), np.float32(y)\n","\n","# time-based split (80/20)\n","T_total = len(features)\n","T_train = int(T_total * 0.8)\n","train_feats = features[:T_train]\n","train_targs = targets[:T_train]\n","val_feats = features[T_train - cfg.seq_len:]  # ensure enough context\n","val_targs = targets[T_train - cfg.seq_len:]\n","\n","btc_train_ds = WindowedSeqDataset(train_feats, train_targs, cfg.seq_len)\n","btc_val_ds = WindowedSeqDataset(val_feats, val_targs, cfg.seq_len)\n","\n","train_loader = DataLoader(btc_train_ds, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(btc_val_ds, batch_size=cfg.batch_size, shuffle=False, drop_last=False)\n","\n","print({\"train_batches\": len(train_loader), \"val_batches\": len(val_loader)})\n","\n","# 4) Reinitialize model and optimizer for BTC features\n","cfg.feature_dim = Fdim\n","model = HRM(feature_dim=cfg.feature_dim, d_model=cfg.d_model).to(device)\n","opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","model, cfg.feature_dim\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ACT and loss weights configuration\n","# Extend cfg with ACT params and loss weights (can be tuned)\n","setattr(cfg, \"w_r\", 1.0)          # regression weight\n","setattr(cfg, \"w_d\", 0.25)         # direction BCE weight\n","setattr(cfg, \"w_q\", 0.1)          # Q-head BCE weight\n","setattr(cfg, \"act_Mmax\", 4)       # maximum segments per episode\n","setattr(cfg, \"act_eps\", 0.2)      # epsilon prob to sample larger Mmin\n","setattr(cfg, \"act_ponder\", 0.001) # ponder cost per extra segment\n","setattr(cfg, \"act_use_dir\", True) # use direction label for reward\n","\n","cfg.w_r, cfg.w_d, cfg.w_q, cfg.act_Mmax, cfg.act_eps, cfg.act_ponder, cfg.act_use_dir\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extend HRM with Q-head and direction head\n","class HRM_ACT(HRM):\n","    def __init__(self, feature_dim: int, d_model: int = 256, n_heads: int = 8, n_layers_low: int = 4, n_layers_high: int = 4, dim_ff: int = None):\n","        super().__init__(feature_dim, d_model, n_heads, n_layers_low, n_layers_high, dim_ff)\n","        self.dir_head = nn.Linear(d_model, 1)  # direction logits\n","        self.q_head = nn.Linear(d_model, 2)    # Q(halt), Q(continue)\n","\n","    def forward_segment(self, zH, zL, x, N: int, T: int):\n","        x_emb = self.input_net(x)\n","        with torch.no_grad():\n","            for i in range(N * T - 1):\n","                zL = self.low(x_emb + zL + zH)\n","                if (i + 1) % T == 0:\n","                    zH = self.high(zH + zL)\n","        # 1-step grad\n","        zL = self.low(x_emb + zL + zH)\n","        zH = self.high(zH + zL)\n","        pooled = zH.mean(dim=1)\n","        reg = self.reg_head(pooled).squeeze(-1)\n","        dir_logit = self.dir_head(pooled).squeeze(-1)\n","        q = self.q_head(pooled)\n","        return (zH, zL), reg, dir_logit, q\n","\n","\n","# Reinit model as HRM_ACT\n","model = HRM_ACT(feature_dim=cfg.feature_dim, d_model=cfg.d_model).to(device)\n","opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Training with ACT (Q-learning targets and halting)\n","\n","def bce_logits(logits, target):\n","    return F.binary_cross_entropy_with_logits(logits, target)\n","\n","\n","def train_one_epoch_act(epoch):\n","    model.train()\n","    total_loss = 0.0\n","    count = 0\n","    for xb, yb in train_loader:\n","        xb = xb.to(device)\n","        yb = yb.to(device)\n","        y_dir = (yb >= 0).float()\n","        B = xb.size(0)\n","\n","        # Choose M_min stochastically per paper\n","        if np.random.rand() < cfg.act_eps:\n","            M_min = np.random.randint(2, cfg.act_Mmax + 1)\n","        else:\n","            M_min = 1\n","\n","        # Initialize hidden states per sample\n","        zH, zL = model.init_state(B, xb.size(1), device)\n","        halted = torch.zeros(B, dtype=torch.bool, device=device)\n","        last_reg = torch.zeros(B, device=device)\n","        last_dir_logit = torch.zeros(B, device=device)\n","\n","        for m in range(cfg.act_Mmax):\n","            (zH, zL), reg, dir_logit, q = model.forward_segment(zH, zL, xb, cfg.n_cycles, cfg.t_steps)\n","\n","            # Deep supervision regression & direction losses on active samples\n","            mask = ~halted\n","            L = torch.tensor(0.0, device=device)\n","            if mask.any():\n","                L = L + cfg.w_r * log_cosh_loss(reg[mask], yb[mask])\n","                if cfg.act_use_dir:\n","                    L = L + cfg.w_d * bce_logits(dir_logit[mask], y_dir[mask])\n","\n","            # Q-learning targets\n","            # Compute episodic rewards: if halt now, reward = 1{correct direction}; else 0\n","            with torch.no_grad():\n","                correct = ((dir_logit >= 0).float() == y_dir).float()\n","                G_halt = correct  # binary reward\n","                # continue target will be bootstrapped with next q (set later)\n","\n","            # Decide actions (halt/continue)\n","            q_halt = q[:, 0]\n","            q_cont = q[:, 1]\n","            choose_halt = (q_halt >= q_cont) & (m + 1 >= M_min)\n","            # Force halt at last step\n","            if m == cfg.act_Mmax - 1:\n","                choose_halt = torch.ones_like(choose_halt, dtype=torch.bool)\n","\n","            # Build Q targets\n","            # For samples that halt now: target is immediate reward\n","            # For continue: bootstrap with max next-step Q on next segment (approx via current q to keep simple)\n","            with torch.no_grad():\n","                G = torch.zeros_like(q)\n","                # Halt targets\n","                G[:, 0] = G_halt\n","                # Continue targets: approximate with current next-step estimate using max(q)\n","                # (In practice, you might compute q_next from next segment. Here we keep 1-step target simple.)\n","                G[:, 1] = torch.maximum(q_halt, q_cont).detach()\n","\n","            L = L + cfg.w_q * F.binary_cross_entropy_with_logits(q, G)\n","\n","            # Ponder cost for continued, unhalted samples\n","            if m + 1 > M_min:\n","                L = L + cfg.act_ponder * (~choose_halt).float().mean()\n","\n","            L.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n","            opt.step(); opt.zero_grad(set_to_none=True)\n","\n","            # Update halting\n","            halted = halted | choose_halt\n","            zH = zH.detach(); zL = zL.detach()\n","            last_reg = reg.detach()\n","            last_dir_logit = dir_logit.detach()\n","\n","            if halted.all():\n","                break\n","\n","        total_loss += L.item()\n","        count += 1\n","\n","    print(f\"epoch {epoch} train(ACT) loss: {total_loss / max(count,1):.4f}\")\n","\n","\n","def evaluate_act():\n","    model.eval()\n","    losses = []\n","    maes = []\n","    accs = []\n","    with torch.no_grad():\n","        for xb, yb in val_loader:\n","            xb = xb.to(device)\n","            yb = yb.to(device)\n","            y_dir = (yb >= 0).float()\n","            zH, zL = model.init_state(xb.size(0), xb.size(1), device)\n","            halted = torch.zeros(xb.size(0), dtype=torch.bool, device=device)\n","            reg = torch.zeros_like(yb)\n","            dir_logit = torch.zeros_like(yb)\n","            for m in range(cfg.act_Mmax):\n","                (zH, zL), reg_m, dir_logit_m, q = model.forward_segment(zH, zL, xb, cfg.n_cycles, cfg.t_steps)\n","                # ACT halting rule at eval (greedy)\n","                q_halt = q[:, 0]\n","                q_cont = q[:, 1]\n","                choose_halt = (q_halt >= q_cont)\n","                # commit predictions when halting and not already halted\n","                commit = choose_halt & (~halted)\n","                reg[commit] = reg_m[commit]\n","                dir_logit[commit] = dir_logit_m[commit]\n","                halted = halted | choose_halt\n","                zH = zH.detach(); zL = zL.detach()\n","                if halted.all():\n","                    break\n","            # fallback for any that never halted\n","            still = ~halted\n","            if still.any():\n","                reg[still] = reg_m[still]\n","                dir_logit[still] = dir_logit_m[still]\n","            loss = log_cosh_loss(reg, yb).item()\n","            mae = (reg - yb).abs().mean().item()\n","            acc = (((dir_logit >= 0).float() == y_dir).float().mean().item())\n","            losses.append(loss); maes.append(mae); accs.append(acc)\n","    print(f\"val(ACT) loss: {np.mean(losses):.4f} | MAE: {np.mean(maes):.6f} | Dir Acc: {np.mean(accs):.4f}\")\n","\n","\n","for epoch in range(1, cfg.max_epochs + 1):\n","    train_one_epoch_act(epoch)\n","    evaluate_act()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Performance evaluation & visualization (val set)\n","import matplotlib.pyplot as plt\n","\n","@torch.no_grad()\n","def collect_val_predictions(max_batches=None):\n","    model.eval()\n","    preds = []\n","    dirs = []\n","    trues = []\n","    steps_used = []\n","    for bi, (xb, yb) in enumerate(val_loader):\n","        xb = xb.to(device)\n","        yb = yb.to(device)\n","        zH, zL = model.init_state(xb.size(0), xb.size(1), device)\n","        halted = torch.zeros(xb.size(0), dtype=torch.bool, device=device)\n","        reg = torch.zeros_like(yb)\n","        dir_logit = torch.zeros_like(yb)\n","        steps = torch.zeros_like(yb, dtype=torch.long)\n","        for m in range(cfg.act_Mmax):\n","            (zH, zL), reg_m, dir_logit_m, q = model.forward_segment(zH, zL, xb, cfg.n_cycles, cfg.t_steps)\n","            q_halt = q[:, 0]\n","            q_cont = q[:, 1]\n","            choose_halt = (q_halt >= q_cont)\n","            commit = choose_halt & (~halted)\n","            reg[commit] = reg_m[commit]\n","            dir_logit[commit] = dir_logit_m[commit]\n","            steps[commit] = m + 1\n","            halted = halted | choose_halt\n","            zH = zH.detach(); zL = zL.detach()\n","            if halted.all():\n","                break\n","        still = ~halted\n","        if still.any():\n","            reg[still] = reg_m[still]\n","            dir_logit[still] = dir_logit_m[still]\n","            steps[still] = cfg.act_Mmax\n","        preds.append(reg.cpu())\n","        dirs.append(dir_logit.cpu())\n","        trues.append(yb.cpu())\n","        steps_used.append(steps.cpu())\n","        if max_batches is not None and (bi + 1) >= max_batches:\n","            break\n","    return torch.cat(preds), torch.cat(dirs), torch.cat(trues), torch.cat(steps_used)\n","\n","\n","preds, dir_logits, trues, steps_used = collect_val_predictions()\n","y_dir = (trues >= 0).float()\n","acc = ((dir_logits >= 0).float() == y_dir).float().mean().item()\n","mae = (preds - trues).abs().mean().item()\n","rmse = torch.sqrt(((preds - trues) ** 2).mean()).item()\n","cor = np.corrcoef(preds.numpy(), trues.numpy())[0,1]\n","\n","print({\"val_dir_acc\": round(acc, 4), \"val_mae\": round(mae, 6), \"val_rmse\": round(rmse, 6), \"val_corr\": float(cor)})\n","print({\"mean_steps\": float(steps_used.float().mean()), \"pct_halt_1\": float((steps_used == 1).float().mean())})\n","\n","# Simple PnL proxy: position = sign(pred), PnL = position * true_return - spread_cost\n","# Spread cost proxy (very small for crypto hourly): c per trade when position changes\n","pos = torch.sign(preds).numpy()\n","ret = trues.numpy()\n","trade = np.abs(np.diff(pos, prepend=0)) > 0\n","c = 0.0  # set to small cost if desired, e.g., 1e-5\n","pnl = pos * ret - c * trade.astype(np.float32)\n","cum_pnl = pnl.cumsum()\n","\n","fig, axs = plt.subplots(3, 1, figsize=(10, 10), constrained_layout=True)\n","axs[0].plot(trues.numpy(), label=\"true ret\", alpha=0.7)\n","axs[0].plot(preds.numpy(), label=\"pred ret\", alpha=0.7)\n","axs[0].legend(); axs[0].set_title(\"Returns: true vs pred (val)\")\n","axs[1].plot(cum_pnl, color=\"tab:green\"); axs[1].set_title(\"Cumulative PnL (val)\")\n","axs[2].hist(steps_used.numpy(), bins=np.arange(0.5, cfg.act_Mmax + 1.5), rwidth=0.8)\n","axs[2].set_xticks(list(range(1, cfg.act_Mmax + 1)))\n","axs[2].set_title(\"ACT steps used distribution (val)\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Foundation-Py-Default","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}