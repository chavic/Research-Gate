{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Selection Predictive Value Testing\n",
        "\n",
        "This notebook measures how well our daily selection lists foresee future breakouts. We’ll join historical selections with realized forward returns and compute precision/recall metrics for big moves (e.g., 10×), along with portfolio-style performance diagnostics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow Overview\n",
        "1. **Load selection log** – historical picks and scores per rebalance date.\n",
        "2. **Compute future returns** – join QC history to calculate 7d/30d forward returns.\n",
        "3. **Label outcomes** – classify 10×, breakouts, or neutral.\n",
        "4. **Evaluate precision/recall** – check how many hits we captured vs. misses.\n",
        "5. **Portfolio backtest** – compare selection returns against baselines.\n",
        "6. **Diagnostics** – highlight misses, false positives, and component contributions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from QuantConnect import Resolution  # type: ignore[import]\n",
        "    from QuantConnect.Research import QuantBook  # type: ignore[import]\n",
        "except ImportError as exc:\n",
        "    raise RuntimeError(\"Run inside a QuantConnect Research environment to evaluate selection accuracy.\") from exc\n",
        "\n",
        "qb = QuantBook()\n",
        "SELECTION_LOG_FILE = Path(\"data/native_features/selection_log.parquet\")\n",
        "FORWARD_WINDOWS = {\"ret_7d\": 7, \"ret_30d\": 30}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UNIVERSE_LOG_FILE = Path(\"data/native_features/universe_log.parquet\")\n",
        "\n",
        "missing_files = [path for path in [SELECTION_LOG_FILE, UNIVERSE_LOG_FILE] if not path.exists()]\n",
        "if missing_files:\n",
        "    raise FileNotFoundError(\n",
        "        \"Missing data logs: \" + \", \".join(str(path) for path in missing_files) + \". Run the selection notebook to generate them.\"\n",
        "    )\n",
        "\n",
        "selection_log = pd.read_parquet(SELECTION_LOG_FILE)\n",
        "universe_log = pd.read_parquet(UNIVERSE_LOG_FILE)\n",
        "\n",
        "for df in (selection_log, universe_log):\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
        "\n",
        "selection_log = selection_log.sort_values(\"date\")\n",
        "universe_log = universe_log.sort_values(\"date\")\n",
        "selection_log.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_forward_returns(symbol, dates, windows):\n",
        "    quant_symbol = qb.AddCrypto(symbol, Resolution.Hour).Symbol\n",
        "    history = qb.History(quant_symbol, dates.min(), dates.max() + timedelta(days=max(windows.values())), Resolution.Hour)\n",
        "    if history.empty:\n",
        "        return pd.DataFrame()\n",
        "    closes = history.close.unstack(level=0).tz_localize(None)[quant_symbol.Value]\n",
        "    returns = pd.DataFrame(index=dates)\n",
        "    for label, days in windows.items():\n",
        "        shifted = closes.shift(-days * 24)\n",
        "        aligned = pd.concat([closes, shifted], axis=1).reindex(index=dates)\n",
        "        returns[label] = (aligned.iloc[:, 1] / aligned.iloc[:, 0]) - 1\n",
        "    returns.index.name = \"date\"\n",
        "    returns[\"symbol\"] = symbol\n",
        "    return returns.reset_index()\n",
        "\n",
        "forward_frames = []\n",
        "for symbol in selection_log[\"symbol\"].unique():\n",
        "    dates = selection_log.loc[selection_log[\"symbol\"] == symbol, \"date\"]\n",
        "    frame = compute_forward_returns(symbol, dates, FORWARD_WINDOWS)\n",
        "    if not frame.empty:\n",
        "        forward_frames.append(frame)\n",
        "\n",
        "forward_returns = (\n",
        "    pd.concat(forward_frames, axis=0, ignore_index=True)\n",
        "    if forward_frames\n",
        "    else pd.DataFrame(columns=[\"date\", \"symbol\", *FORWARD_WINDOWS.keys()])\n",
        ")\n",
        "selection_with_returns = selection_log.merge(forward_returns, on=[\"date\", \"symbol\"], how=\"left\")\n",
        "\n",
        "universe_frames = []\n",
        "for symbol in universe_log[\"symbol\"].unique():\n",
        "    dates = universe_log.loc[universe_log[\"symbol\"] == symbol, \"date\"]\n",
        "    frame = compute_forward_returns(symbol, dates, FORWARD_WINDOWS)\n",
        "    if not frame.empty:\n",
        "        universe_frames.append(frame)\n",
        "\n",
        "universe_forward_returns = (\n",
        "    pd.concat(universe_frames, axis=0, ignore_index=True)\n",
        "    if universe_frames\n",
        "    else pd.DataFrame(columns=[\"date\", \"symbol\", *FORWARD_WINDOWS.keys()])\n",
        ")\n",
        "universe_with_returns = universe_log.merge(universe_forward_returns, on=[\"date\", \"symbol\"], how=\"left\")\n",
        "\n",
        "selection_with_returns.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def label_breakouts(row, thresholds):\n",
        "    if row[\"ret_30d\"] >= thresholds.get(\"ten_x\", 10.0):\n",
        "        return \"10x\"\n",
        "    if row[\"ret_30d\"] >= thresholds.get(\"breakout\", 2.0):\n",
        "        return \"breakout\"\n",
        "    if row[\"ret_7d\"] >= thresholds.get(\"short_term\", 0.5):\n",
        "        return \"short_surge\"\n",
        "    return \"neutral\"\n",
        "\n",
        "THRESHOLDS = {\"ten_x\": 10.0, \"breakout\": 2.0, \"short_term\": 0.5}\n",
        "for df in (selection_with_returns, universe_with_returns):\n",
        "    df[\"label\"] = df.apply(label_breakouts, axis=1, thresholds=THRESHOLDS)\n",
        "    df[\"hit\"] = df[\"label\"].isin([\"10x\", \"breakout\"])\n",
        "\n",
        "selection_with_returns.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision = selection_with_returns[\"hit\"].mean()\n",
        "\n",
        "hits_total = universe_with_returns[universe_with_returns[\"hit\"]]\n",
        "hits_with_flags = pd.DataFrame()\n",
        "if hits_total.empty:\n",
        "    recall = 0.0\n",
        "else:\n",
        "    selected_pairs = selection_with_returns[[\"date\", \"symbol\"]].copy()\n",
        "    selected_pairs[\"selected\"] = True\n",
        "    hits_with_flags = hits_total.merge(selected_pairs, on=[\"date\", \"symbol\"], how=\"left\")\n",
        "    hits_captured = hits_with_flags[\"selected\"].fillna(False).sum()\n",
        "    recall = hits_captured / len(hits_total)\n",
        "\n",
        "precision, recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missed_hits = hits_with_flags[hits_with_flags[\"selected\"].fillna(False) == False] if not hits_with_flags.empty else pd.DataFrame()\n",
        "missed_hits.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes & Next Steps\n",
        "- Recall now uses `universe_log.parquet`; ensure the selection notebook keeps that log up-to-date (e.g., at each rebalance).\n",
        "- Extend the diagnostics with:\n",
        "  - Confusion matrices per threshold (10×, breakout, short surge).\n",
        "  - Rolling precision/recall plots to monitor drift.\n",
        "  - Portfolio backtests comparing selection vs. baseline baskets.\n",
        "  - Hit/miss breakdowns by feature or component to guide score tuning.\n",
        "- Consider caching forward returns to avoid repeated history pulls during development.\n",
        "- Wire these diagnostics back into the main selection notebook so each research iteration automatically updates the predictive scorecard.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
